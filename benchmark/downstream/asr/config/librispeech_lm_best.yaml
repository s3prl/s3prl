data:
  corpus:                                 # Pass to dataloader
    # The following depends on corpus
    name: 'Librispeech'                   # Specify corpus
    path: '../../datasets/LibriSpeech'
    train_split: ['librispeech-lm-norm.txt'] # Official LM src from LibriSpeech
    #train_split: ['train-clean-100']
    dev_split: ['dev-clean']
    bucketing: True
    batch_size: 128
  text:
    mode: 'character'                     # 'character'/'word == phone'/'subword'
    vocab_file: 'corpus/librispeech_char.txt'

hparas:                                   # Experiment hyper-parameters
  valid_step: 2000
  max_step: 1000000
  optimizer: 'Adam'
  lr: 0.0001
  eps: 0.00000001
  lr_scheduler: 'fixed'                    # 'fixed'/'warmup'

model:                                     # Model architecture
  emb_tying: True                         # https://arxiv.org/pdf/1608.05859.pdf
  emb_dim: 2048
  module: 'LSTM'                           # 'LSTM'/'GRU'
  dim: 2048
  n_layers: 4
  dropout: 0.5
